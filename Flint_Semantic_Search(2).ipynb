{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from pprint import pprint.pprint as pprint\n",
        "import pprint"
      ],
      "metadata": {
        "id": "5m3aA59IiZz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup\n",
        "-----------\n",
        "\n",
        "Run the following series of cells to initialize the required dependancies and \n",
        "load the dataset"
      ],
      "metadata": {
        "id": "AocQe1X6iaPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# ENTER YOUR DATSET AS A PANDAS DATAFRAME NAMED 'df' HERE"
      ],
      "metadata": {
        "id": "wNSk9SaNjLTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  This would be where you choose what document size you want\n",
        "rows = df[\"Body\"][200:500]\n",
        "rows = rows.array.tolist()"
      ],
      "metadata": {
        "id": "j7MA0d4JkTq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face Semantic Search\n",
        "---------"
      ],
      "metadata": {
        "id": "Z81p0Xg84u-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "idHTfKDF4-SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the data and replace the path. Then run the following 2 cells to get the tagged email data for emails 200-500\n",
        "!unzip /content/97e76ea3-797e-4955-8973-20b8f965f924.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tVTVMM66t94",
        "outputId": "41fd3fa6-cd1c-4163-ea8a-67cb90a2126e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/97e76ea3-797e-4955-8973-20b8f965f924.zip\n",
            "  inflating: admin.jsonl             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# This was run in google colab, you may need to adjust the path depending on\n",
        "# your environment\n",
        "filename = \"/content/admin.jsonl\"\n",
        "with open(filename) as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "labled_data= []\n",
        "for s in lines:\n",
        "  result = json.loads(s)\n",
        "  labled_data.append(result)\n",
        "\n",
        "# some of the emails may have been put out of order so this fixes that\n",
        "labled_data.sort(key = lambda x: x['id'])"
      ],
      "metadata": {
        "id": "hY6xwU4NPX1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the form for the output of the function\n",
        "# [[query0,[result0,result1,result2]],[query1,[result0,result1,result2]]...]\n",
        "def run_queries(model_name, queries, rows, similarity,num_results):\n",
        "  # initializes the array that will contain the return value of the function\n",
        "  model_storage = []\n",
        "  for i in range(len(queries)):\n",
        "    model_storage.append([queries[i],[]])\n",
        "\n",
        "  model = SentenceTransformer(model_name)\n",
        "  doc_emb = model.encode(rows)\n",
        "\n",
        "  for i in range(len(queries)):\n",
        "    query_emb = model.encode(queries[i])\n",
        "\n",
        "    # chooses the similarity search. If you want, you can add others\n",
        "    if (similarity == 'dot'):\n",
        "      scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
        "    elif (similarity == 'cos'):\n",
        "      scores = util.cos_sim(query_emb, doc_emb)[0].cpu().tolist()\n",
        "    else:\n",
        "      raise ValueError('invalid similarity! Supported arguments: dot, cos')\n",
        "    \n",
        "    # selects the num_results number best results for the query by similarity\n",
        "    doc_score_pairs = list(zip(rows, scores))\n",
        "    doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
        "    model_storage[i][1] = doc_score_pairs[0:num_results]\n",
        "\n",
        "  return model_storage"
      ],
      "metadata": {
        "id": "J8Ayu5rM7dFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model results is the list produced by run_queries\n",
        "# rows is the original data onverted to a list\n",
        "# labled_data is the docanno labled data\n",
        "def compute_model_score(model_results, rows, labeled_data):\n",
        "  score = 0\n",
        "  for x in model_results:  \n",
        "    # converts between the Doccano document label and the desired semantic search query \n",
        "    if x[0] == \"public releases\":\n",
        "      query = \"public releases (press and state)\"\n",
        "    else:\n",
        "      query = x[0]\n",
        "    \n",
        "    for y in x[1]:\n",
        "      # if there were no lables for the data automatically fail the test\n",
        "      if len(labled_data[rows.index(y[0])][\"label\"]) == 0:\n",
        "        score-=1\n",
        "      else:\n",
        "        # determines if the retrieved document is relevant for the query\n",
        "        if (query in labeled_data[rows.index(y[0])][\"label\"][0]):\n",
        "          score+= 1\n",
        "        else:\n",
        "          score-=1 \n",
        "          \n",
        "  return score    \n"
      ],
      "metadata": {
        "id": "kxnSWgEXPyoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(x[1][0][1][0][0]) # <-- gives actual message\n",
        "#   print(x[1][0][0]) # <-- prints label"
      ],
      "metadata": {
        "id": "iPqdAMER_joE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is where we see which model performed best on the data\n",
        "# Runs all of the models on the documents and sees which ones produce emails\n",
        "# that have tags relevant to the queries. \n",
        "# This cell returns the score of each model for selecting relevant emails for queries.\n",
        "# Note that higher numbers (less negative) are better than smaller ones\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pprint\n",
        "\n",
        "# intimidation is omitted as there is only one instance of it in the dataset\n",
        "queries = [\"taking responsibility\", \n",
        "          #  \"intimidation\", \n",
        "           \"bad judgement because of groupthink\", \n",
        "           \"confusion\", \n",
        "           \"opportunism\",\n",
        "           \"public releases\"]\n",
        "\n",
        "\n",
        "# feel free to add other models here for testing\n",
        "dot_models = [\"sentence-transformers/all-mpnet-base-v2\",\n",
        "              \"sentence-transformers/all-MiniLM-L12-v2\",\n",
        "              \"sentence-transformers/msmarco-bert-base-dot-v5\"]\n",
        "\n",
        "cos_models = [\"sentence-transformers/msmarco-distilbert-cos-v5\",\n",
        "              \"sentence-transformers/msmarco-distilbert-base-v4\"]\n",
        "\n",
        "\n",
        "# this runs the search queries. It can take a really long time\n",
        "dot_model_results = []\n",
        "for x in dot_models:\n",
        "  dot_model_results.append([x,run_queries(x,queries,rows,'dot',5)])\n",
        "\n",
        "cos_model_results = []\n",
        "for x in cos_models:\n",
        "  cos_model_results.append([x,run_queries(x,queries,rows,'cos',5)])\n",
        "\n",
        "\n",
        "# scores models based on their searches and outputs the result\n",
        "all_model_scores = []\n",
        "\n",
        "for x in dot_model_results:\n",
        "  all_model_scores.append((x[0], compute_model_score(x[1],rows,labled_data)))\n",
        "\n",
        "for x in cos_model_results:\n",
        "  all_model_scores.append((x[0], compute_model_score(x[1],rows,labled_data)))\n",
        "\n",
        "pprint.pprint(all_model_scores)\n",
        "\n"
      ],
      "metadata": {
        "id": "6lV_UqlT433v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When num_results=3 these are the scores\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "[('sentence-transformers/all-mpnet-base-v2', -15),\n",
        " ('sentence-transformers/all-MiniLM-L12-v2', -13),\n",
        " ('sentence-transformers/msmarco-bert-base-dot-v5', -9),\n",
        " ('sentence-transformers/msmarco-distilbert-cos-v5', -11),\n",
        " ('sentence-transformers/msmarco-distilbert-base-v4', -11)]\n",
        "\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        " when num_results=5 these are the scores:\n",
        " ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        " [('sentence-transformers/all-mpnet-base-v2', -19),\n",
        " ('sentence-transformers/all-MiniLM-L12-v2', -21),\n",
        " ('sentence-transformers/msmarco-bert-base-dot-v5', -15),\n",
        " ('sentence-transformers/msmarco-distilbert-cos-v5', -21),\n",
        " ('sentence-transformers/msmarco-distilbert-base-v4', -21)]\n",
        " ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        " 'sentence-transformers/msmarco-bert-base-dot-v5' performs best in both trials"
      ],
      "metadata": {
        "id": "OeBqxlYuu3eI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the UI that calls all the other functions and does the actual searches\n",
        "\n",
        "# feel free to add other queries to this list. However, you should make sure\n",
        "# that those are supported in the Doccano tags. \n",
        "queries = [\"taking responsibility\", \n",
        "           \"intimidation\", \n",
        "           \"bad judgement because of groupthink\", \n",
        "           \"confusion\", \n",
        "           \"opportunism\",\n",
        "           \"public releases\"]\n",
        "\n",
        "\n",
        "# choose which documents you want to search on\n",
        "rows2 = df[\"Body\"][:]\n",
        "rows2 = rows2.array.tolist()\n",
        "\n",
        "pprint.pprint(run_queries('sentence-transformers/msmarco-bert-base-dot-v5',queries,rows2,'dot',3))"
      ],
      "metadata": {
        "id": "w-uuBQj11tdb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}